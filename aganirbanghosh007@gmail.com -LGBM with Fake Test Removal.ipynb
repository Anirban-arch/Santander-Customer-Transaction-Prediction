{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "_ac5BJqRWvRM",
    "outputId": "e66144b7-0952-4315-df37-1ba5b6679dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmteX-bwXHP9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6hb7MWEW5Ke"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/test.csv')\n",
    "train_copy = train.copy()\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SCgXptjXMpe"
   },
   "outputs": [],
   "source": [
    "train_y = train_copy['target'].values\n",
    "train_X_column_name = train_copy.drop(['target', 'ID_code'], axis=1).columns\n",
    "train_X = train_copy.drop(['target', 'ID_code'], axis=1).values\n",
    "test_X = test_copy.drop(['ID_code'], axis=1).values\n",
    "train_X_copy = train_X.copy()\n",
    "test_X_copy = test_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahm8rEcpXWE1"
   },
   "outputs": [],
   "source": [
    "unique_samples = []\n",
    "unique_count = np.zeros_like(test_X)\n",
    "for feature in range(test_X.shape[1]):\n",
    "    _, index_, count_ = np.unique(test_X[:, feature], return_index=True, return_counts=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "real_sample_index = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_sample_index = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "test_X_real = test_X[real_sample_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KvfJfjqHXbQ0",
    "outputId": "e563095d-5518-4445-f819-ff448a3f7bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100000 real data samples in test set\n",
      "There are 100000 synthetic data samples in test set\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(real_sample_index)) + ' real data samples in test set')\n",
    "print('There are ' + str(len(synthetic_sample_index)) + ' synthetic data samples in test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7Fy52twXeaa"
   },
   "outputs": [],
   "source": [
    "generator_for_each_synthetic_sample = []\n",
    "for cur_sample_index in synthetic_sample_index[:20000]:\n",
    "    cur_synthetic_sample = test_X[cur_sample_index]\n",
    "    potential_generators = test_X_real == cur_synthetic_sample\n",
    "\n",
    "    features_mask = np.sum(potential_generators, axis=0) == 1\n",
    "    verified_generators_mask = np.any(potential_generators[:, features_mask], axis=1)\n",
    "    verified_generators_for_sample = real_sample_index[np.argwhere(verified_generators_mask)[:, 0]]\n",
    "    generator_for_each_synthetic_sample.append(set(verified_generators_for_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "003m7f0jXjAk"
   },
   "outputs": [],
   "source": [
    "gen = generator_for_each_synthetic_sample[0]\n",
    "for x in generator_for_each_synthetic_sample:\n",
    "    if gen.intersection(x):\n",
    "        gen = gen.union(x)\n",
    "\n",
    "LB = generator_for_each_synthetic_sample[1]\n",
    "for x in generator_for_each_synthetic_sample:\n",
    "    if LB.intersection(x):\n",
    "        LB = LB.union(x)\n",
    "\n",
    "LB = list(LB)\n",
    "gen = list(gen)\n",
    "full = np.concatenate([train_X, np.concatenate([test_X[LB], test_X[gen]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tbPkznSfXmTf",
    "outputId": "4c84e499-fd41-4e92-84e2-ebb9021ca90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50000 data samples for public score in real data set\n",
      "There are 50000 data samples for private score in real data set\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(LB)) + ' data samples for public score in real data set')\n",
    "print('There are ' + str(len(gen)) + ' data samples for private score in real data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYKqm107Xqjw"
   },
   "outputs": [],
   "source": [
    "full = pd.DataFrame(full)\n",
    "full.columns = train_X_column_name\n",
    "train_X = pd.DataFrame(train_X)\n",
    "train_X.columns = train_X_column_name\n",
    "test_X = pd.DataFrame(test_X)\n",
    "test_X .columns = train_X_column_name\n",
    "\n",
    "for feat in ['var_' + str(x) for x in range(200)]:\n",
    "    count_values = full.groupby(feat)[feat].count()\n",
    "    train_X['new_' + feat] = count_values.loc[train_X[feat]].values\n",
    "    test_X['new_' + feat] = count_values.loc[test_X[feat]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HEAIA1UXvro"
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "param = {\n",
    "    'num_leaves': 8,\n",
    "    'min_data_in_leaf': 17,\n",
    "    'learning_rate': 0.01,\n",
    "    'min_sum_hessian_in_leaf': 9.67,\n",
    "    'bagging_fraction': 0.8329,\n",
    "    'bagging_freq': 2,\n",
    "    'feature_fraction': 1,\n",
    "    'lambda_l1': 0.6426,\n",
    "    'lambda_l2': 0.3067,\n",
    "    'min_gain_to_split': 0.02832,\n",
    "    'max_depth': -1,\n",
    "    'seed': seed,\n",
    "    'feature_fraction_seed': seed,\n",
    "    'bagging_seed': seed,\n",
    "    'drop_seed': seed,\n",
    "    'data_random_seed': seed,\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': True,\n",
    "    'save_binary': True,\n",
    "    'boost_from_average': 'false',\n",
    "    'num_threads': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwBN5zbuXwhS"
   },
   "outputs": [],
   "source": [
    "iterations = 110\n",
    "test_hat = np.zeros([200000, 200])\n",
    "i = 0\n",
    "for feature in ['var_' + str(x) for x in range(200)]:  # loop over all features\n",
    "    # print(feature)\n",
    "    feat_choices = [feature, 'new_' + feature]\n",
    "    lgb_train = lgb.Dataset(train_X[feat_choices], train_y)\n",
    "    gbm = lgb.train(param, lgb_train, iterations, verbose_eval=-1)\n",
    "    test_hat[:, i] = gbm.predict(test_X[feat_choices], num_iteration=gbm.best_iteration)\n",
    "    i += 1\n",
    "\n",
    "sub_preds = test_hat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PoKB4f8hxJR"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ID_code'] = test_copy['ID_code']\n",
    "sub['target'] = sub_preds\n",
    "sub.to_csv('/content/drive/My Drive/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
